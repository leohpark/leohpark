{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPztTtkh7Q6fB3hSKcxZ2nz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leohpark/leohpark/blob/main/Burger_and_Fries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A very simple notebook for testing out OpenAI's new function calls. Very intuitive and relatable context of a Hamburger and Fries ordering function. Allows you to see what function parameters, names, and values either assist, or detract, from your ability to make a steerable chatbot based on the \"prompt\" elements of a function parameter.\n",
        "\n",
        "\n",
        "###Disclaimer\n",
        "Unless required by applicable law or agreed to in writing, the code provided in this notebook is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."
      ],
      "metadata": {
        "id": "iV4BgiWzzOh-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvHdrCTLzM54"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#put your open AI key in the brackets\n",
        "import openai\n",
        "import json\n",
        "OPENAI_KEY = \"\"\n",
        "openai.api_key = OPENAI_KEY\n"
      ],
      "metadata": {
        "id": "-GAaWLx0zlZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm authentication was successful\n",
        "openai.Engine.list()['data'][0]"
      ],
      "metadata": {
        "id": "euSjfVffzsNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function and System Message\n",
        "\n",
        "Write your function below. Put in different object types, property names, and descriptions to see how it steers the chatbot.\n",
        "\n",
        "My brief expereince is that Description fields greatly increase the bot's propensity to add to the Required function fields, but indiscriminately. The \"Fine Tuning\" seems very aggressive at matching in a \"keyword\" fashion without taking semantic intent into account.\n",
        "\n",
        "Adding more description and instructions in the System Message seems to help in limiting introduction of bad/incompatible data for function passing.\n",
        "\n",
        "Lastly, there are some blank variable assignments to clear out old values, as you will see below the code is just run in an infinite \"While\" loop with no end or error handling, or cleanup. There are proper ways of handling this, which I don't know."
      ],
      "metadata": {
        "id": "TGeG8cuJz-IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define functions here\n",
        "functions = [\n",
        "        {\n",
        "        \"name\": \"hamburger_order\",\n",
        "        \"description\": \"Gathers information for a custom hamburger and fries\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"double_patty\": {\n",
        "                    \"type\": \"boolean\",\n",
        "                    \"description\": \"whether to include two patties or one\",\n",
        "                },\n",
        "                \"burger_cooked\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"medium rare\", \"medium\", \"medium well\", \"well done\"],\n",
        "                    \"description\": \"The doneness of the hamburger the user asks for. Medium rare is pink in the center, medium is slightly pink. medium well is cooked through and not pink, and well done is grey and charred.\",\n",
        "                },\n",
        "                \"cheese\": {\"type\": \"boolean\", \"description\": \"Whether to include cheese.\",},\n",
        "                \"fries\": {\"enum\": [\"no fries\", \"small\", \"medium\", \"large\"], \"description\": \"Only the freshest potatoes.\"}\n",
        "                          },\n",
        "            \"required\": [\"double_patty\", \"burger_cooked\", \"cheese\", \"fries\"]\n",
        "                      },\n",
        "        },\n",
        "        ]"
      ],
      "metadata": {
        "id": "udY2DjR1zyiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sculpt your system messages prompts here!\n",
        "#Run this to clear message variables.\n",
        "messages = [ {\"role\": \"system\", \"content\":\n",
        "              \"\"\"\n",
        "              You are a helpful order taking burgerbot. Greet the user and ask for their order.\n",
        "              On the menu today:\n",
        "                Hamburgers - Single or Double Patty. With or without cheese. Cooked to order.\n",
        "                Fries - Plain potatoes only. Simple but a Classic. Comes in small, medium, or large.\n",
        "              Confirm with the User any function parameters that aren't explicitly mentioned in their message.\n",
        "              Confirm the order before you make a function call.\"\"\"\n",
        "              } ]\n",
        "greetings = []\n",
        "greetings_response = []\n",
        "reply = []\n",
        "print(f\"ChatGPT: {reply}\")"
      ],
      "metadata": {
        "id": "y-S1yB-ez7B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the meat of the notebook. It greets the user, then just infinitely asks for additional info, allowing you to experiement with function data collection. When it thinks a function call is appropriate, the bot will return the Function Arguments it has collected.\n",
        "\n",
        "You have to interrupt the while loop manually at some point in order to disengage with the bot, as there is no end/completion condition. Alternatately, the API connection may time out.\n",
        "\n",
        "If you converse too long, you may reach the model's context limit and things may get unpredictable."
      ],
      "metadata": {
        "id": "WBiUgdQOz5co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the bot does is provide a greeting based on the System Message. If engaged on the topic of foods,\n",
        "# It will generally attempt to complete an order. Once it thinks a function call is appropriate, it will\n",
        "# spit out the Function Arguments, so that you can evaluate what it collected.\n",
        "greetings = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    temperature= 0.3,\n",
        "    messages=messages,\n",
        "    functions = functions,\n",
        "    max_tokens = 250,\n",
        ")\n",
        "greetings_response = greetings.choices[0].message.content\n",
        "print(f\"ChatGPT: {greetings_response}\")\n",
        "messages.append({\"role\": \"assistant\", \"content\": greetings_response})\n",
        "while True:\n",
        "    message = input(\"User : \")\n",
        "    if message:\n",
        "        messages.append(\n",
        "            {\"role\": \"user\", \"content\": message},\n",
        "        )\n",
        "        chat = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            temperature= 0.2,\n",
        "            messages=messages,\n",
        "            functions = functions,\n",
        "            max_tokens = 250,\n",
        "        )\n",
        "    reply = chat.choices[0].message.content\n",
        "    reply_blob = chat[\"choices\"][0][\"message\"]\n",
        "    print(f\"ChatGPT: {reply}\")\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    if reply_blob.get(\"function_call\"):\n",
        "      function_data = chat.choices[0].message.function_call\n",
        "      print(f\"ChatGPT: {function_data}\")"
      ],
      "metadata": {
        "id": "0GDjsM1C04tu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}